何凯明的一张图让我瞬间茅塞顿开，在经典的FNN架构中，除了避免过拟合而认为屏蔽部分节点的行为之外，都是全连接层， 那么是否存在一个可能，我们建立一个只局部处理每个部分，在把所有部分拼接起来的新层！！！这是很自然、非常自然就能想到的可能性！这也一定是计算机先贤想到卷积层的路径，因为这不就是卷积层吗！！！卷积层的本质不就是每次只处理一部分输入再拼接起来吗！卷积核就是原本的FNN参数矩阵！由于卷积处理一部分时选择向量时实现了跨行连续选择，使得空间中相近有关联的东西在向量中确实被有关联的一起处理了，而不是像FNN一样转为大向量后丢失了不同行之间的邻居之间的关联！！！