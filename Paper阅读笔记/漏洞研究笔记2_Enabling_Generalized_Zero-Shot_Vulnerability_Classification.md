这个笔记包含了对算法核心流程123步的更深入的理解, 试图理解这些向量都在干啥, 而不仅仅是宏观地说诸如"某某步加强了模型对xx的理解能力"的这类浮于表面的论述.
## **1. 上下文语义表示（Contextualized Semantic Representation）**

通过GraphCodeBERT, 可以将输入token映射形成 768 维的隐藏向量 (768 这个超参数的确定来自先前研究 )

对于每个元素 (一段代码x / 一个标签y / 一个描述d ), 可能由多个token构成, 每个token都会形成一个隐藏向量, 所以每个元素我们都得到了一个序列, 或者说矩阵. 这样太复杂了, 我了简化处理, 我们各个token取平均即可, 从而每个元素只会映射成一个向量(**疑问:这样处理的话, 那不就相当于用所有token平等的表示这段实例了吗,然而代码实例中大部分内容压根和漏洞无关啊, 错误处的token本身就已经在GraphCodeBERT的处理过程中包含了他所需的上下文信息, 引入大量非错误处的token只会冲淡这个实例中的错误信息,那还怎么用于判断分类?**). 
(更新: 这是我刚仔细研究这里时发出的疑问, 后来研究到第三步后解决了这个疑问, 具体解决我写到了第三步中)

GraphCodeBERT是别人已经做好了的成熟的研究,因此作者只是给出了一个流程图示,并未对其过程进行详细描述, 因此我们也不必关注其实现细节, 在这个研究中, GraphCodeBERT仅仅起到了一个映射工具的作用而已

对于得到的输出, 被按类合并为了矩阵,记作$\tilde{x_i}^s$,$\tilde{y}^s$,$\tilde{d}^s$, $\tilde{d}^u$, 分别代表第i个已见类的所有实例的向量构成的矩阵, 所有已见类标签向量构成的矩阵, 所有已见描述向量构成的矩阵, 所有未见描述向量构成的矩阵.

**疑惑,标签y为什么要向量化, 标签本身就是名字啊, 它本身就没有任何含义啊, 这里向量化是在做什么**


## **2. 语义投影（Semantic Projection）**
#### **整体流程概述**

在上一步中, 模型把已见类(SC)的描述投影到了一个语义空间中, (这个很显然, transformer的第一步就是把输入投影到语义空间中) 模型也把未见类(UC)的描述投影到了另一个语义空间中, 那么问题很显然, 两个语义空间需要合并, 这样模型才能工作,  否则模型仅仅理解各个SC描述之间的关系和各个UC描述之间的关系, 却不理解SC元素和UC元素之间的关系. 那么自然无法把从SC中学习到的知识应用于UC. 合并后生成的新语义表示, 是同一语义空间下的SC和UC向量, 称之为"原型".

论文中把上述步骤称为语义投影（Semantic Projection）, 因为完成合并的方式是把两个空间中的语义坐标投影到了同一个空间中, 需要将已见类和未见类的描述矩阵组合起来,记为 \($\tilde{d} = [\tilde{d}^s, \tilde{d}^u]$\)。语义投影的过程包括**Transformer编码器处理**和**VAE建模**两个阶段。

**到这里, 完全理解语义投影的动机和意义了, 还知道这是几乎所有ZSL方法都要进行的一步, 具体做法操作方法都是经典的, 然而还剩一个地方不懂,那就是"这样为什么是对的呢?",也就是"下面这个经典方法到底是为什么能实现预期目的的?"** 回答这个小问题学习一下ZSL方法本身了, 不过既然已经知道了动机和结果的意义, 具体的实现细节倒也不影响对论文的理解, 因此在笔记中跳过这部分, 将其放入本文后面的附录. (跳过这部分的另一个原因是操作过程本身由于我知其然不知其所以然, 所以除了技术细节本身外也有什么别的可以多说的, 因此这段笔记质量较低).

总之，我们语义投影将描述映射到共享语义空间，生成的原型 \($\hat{d}$\) 和 \($\hat{y}^s$\) 包含已见类和未见类的语义关系。这些原型将在后续步骤（如原型引导适应）中指导实例表示的调整，从而实现从已见类到未见类的知识转移。

# 3.原型引导迁移

难得搞懂了一部分,这部分好复杂

我们通过以上方法已经获得了漏洞描述原型构成的矩阵$\hat{d}$, 但我们还不能直接用, 那就是我在第一步中提出的疑惑"对$x_{ij}$的确定太过鲁莽, 竟然每个代码token的向量中点就是描述这整个代码实例的下标了, 大部分token压根和错误无关也被纳入考虑,  坐标向无关方向偏移这么多, 这不会影响对漏洞类型的定位吗?这样我们就算算好了$\hat{d}$也很难得出靠谱的结果"
一个想法是如果我们只把引起错误的token纳入计算即可, 那么我们如何判断引起错误的token呢? 一个token是否错误不应该直接和某个漏洞原型相比, 因为一个原型向量包含了很多信息, 代表了这个实例的整个描述, 还包含了其他实例的相关信息, 但显然描述本身也有更重要的部分和更不重要的部分, 所以我们应该从所有原型中提取出核心信息, 也就是这些描述的核心语义成分, 然后在把与这些语义成分相近的token视为可能引起错误的代码token, 并为其赋予高权重, 为没有错误的token赋予低权重, 然后求加权平均数作为$x_{ij}$, 这样就合理多了. **这样$x_{ij}$就代表了这段代码示例中的错误发生处在语义空间中的坐标**
所以我们第一问的疑惑确实是对的, 那就是直接取平均数确实不好, 所以本文也确实不是这么做的, 实际上的$x_{ij}$是通过在本步骤中通过原型来引导确认权重, 然后取加权平均的.甚至在后续的测试中正好发现去除这一步会导致准确率直接降低为0, 所以直接取平均数不是"不好", 而是完完全全错了. 由此, 疑问解决

可算是看懂这个流程了, 流程想清楚了, 下面是具体步骤

首先, 原文按照参考文献中的做法，使用了一个“语义成分提取器”便完成了目的, 从原型中提取出了不同的语义成分
$$C = \text{Softmax}\bigl(W_5 \,\cdot\, \text{ReLU}\bigl(W_4 (\hat{d}\,\cdot\,W_3)^T\bigr)\bigr) (\hat{d}\,\cdot\,W_3)$$
组成漏洞实例$x_{ij}$的是一串token序列, 其中的第z个token记为$h_z$, 每个token也就是一个最基本的代码词义单元, 那么这个token"有多么可能是引发错误的核心token",就是其和关键语义矩阵C中任意向量的相近程度的最大值. 自然而言可以表示成$\max_{l}(\text{cos}(h_z, C_l))$, 然后经过乘上用来调节算法的超参数即可得到第z个token$h_z$的权重

$$ \quad \text{weight}_z = \text{Softmax}\bigl(\alpha \cdot \beta \cdot \max_{l}(\text{cos}(h_z, C_l))\bigr)$$
然后向我们之前所说的那样取一个加权平均即可
$$ \quad \hat{x}^s_i = \sum_{z=1}^{Z} h_z \cdot \text{weight}_z$$
由此, 我们就利用原型, 为代码实例给定了一个足够好的描述向量,  这个描述向量蕴含了最核心的错处, 由此, 注意力权重能更好地对准漏洞分类所需的关键信息，这一步**Prototype-guided Adaptation (PA)** 很好的解决了语义丢失的问题

由此, 除了对操作细节不清楚外, 如果没搞错什么的话那就已经搞懂了这个流程, 后面的第四第五步只是通过构造损失函数从而提高模型表现而已, 此前就已经理解,  不再赘述






# 附录
技术细节, 不重要, 不用看, 我当时写这些是为了边写边思考而已, 事实也确实如此, 在写这些的时候我领悟到了上述正文中的内容
### **1. Transformer

- Transformer编码器的第一层会通过线性变换（输入嵌入层）将 \($\tilde{d}$\) 投影到一个内部表示空间。这是Transformer的标准操作，但此时SC和UC的描述仍然是拼接在一起的“独立”向量，尚未发生交互。
- 对于序列中的每个描述向量（无论是SC的 \($\tilde{d}^s$\) 还是UC的 \($\tilde{d}^u$\)），自注意力会计算它与序列中**所有其他向量**（包括SC和UC）的相似性，并根据相似性加权融合这些向量的信息, 通过自注意力，每个描述向量的更新都依赖于序列中其他所有描述向量。
- 使用多头注意力将输入分成多个子空间，每个子空间独立计算注意力，然后拼接结果。这种机制增强了模型捕捉不同语义维度的能力。
- 因为SC和UC的描述是在**同一个Transformer编码器**中处理的，它们共享相同的注意力机制和参数。这种一致性确保它们的表示被投影到**同一语义空间**。

### 2.VAE

VAE通过优化两个主要目标的组合来进行训练：**二元交叉熵（BCE）损失**和**Kullback-Leibler（KL）散度**。这两者共同构成了VAE的总损失，使得模型能够在较低维度的潜在空间中学习输入数据的有意义表示。
#### **二元交叉熵（BCE）损失**
- **目的**：BCE损失用于衡量重构输出$\hat{d}, \hat{y}^s$与原始输入$\tilde{d}_z, y_z^s$之间的差异。它评估VAE重构输入数据的效果，确保模型能够忠实地再现漏洞描述和标签。
- **机制**：对于给定的输入，BCE损失鼓励 \($\hat{d}$\) 与 \($\tilde{d}_z$\) 相似，\($\hat{y}^s$\) 与 \($y_z^s$\) 相似。
- **过程**：
  1. 输入数据$\tilde{d}_z, y_z^s$通过**编码器**，输出定义潜在分布的参数的$\mu, \sigma$。
  2. 从该分布中采样潜在变量 \(z\)（通常使用重参数化技巧：\($z = \mu + \sigma \cdot \epsilon$\)，其中 \($\epsilon \sim \mathcal{N}(0, 1)$\)。
  3. 采样的 \(z\) 被送入**解码器**，生成重构输出$\hat{d}$, $\hat{y}^s$。
  4. BCE损失计算为$\hat{d}, \hat{y}^s$与$(\tilde{d}_z, y_z^s$\)之间的重构误差。

#### ** Kullback-Leibler（KL）散度**
- **目的**：KL散度衡量学习到的潜在分布（由 \($\mu$\) 和 \($\sigma$\) 参数化）与先验分布（通常为标准正态分布 \($\mathcal{N}(0, 1)$\)）之间的差异。
- **公式**：
  $$
  \mathcal{L}_{kl}(\mu, \sigma) = -\frac{1}{2} \sum_{i=1}^{|B|} \left(1 + \log(\sigma_i^2) - \mu_i^2 - \sigma_i^2\right)
  $$
  这里，\(|B|\) 是批量大小，\($\mu_i$\) 和 $sigma_i$是第 \(i\) 个潜在变量的均值和标准差。这个公式看似复杂, 实际上看一下各项前面的正负号就会明白, 这个公式设计成这样只是为了体现学习成果与正态分布的偏差

总损失为:  $$
  \mathcal{L}_{\text{vae}} = \mathcal{L}_{kl} + \mathcal{L}_{\text{bce}}
  $$
显然, 通过梯度下降最小化这个组合损失来训练参数即可。BCE损失确保重构的准确性，而KL散度损失确保模型结果与正态分布对齐。这就是VAE的流程

## 3. 注意力机制

第三步“原型引导的适应”进行的主要操作是：将描述原型 $\hat{d}$ 转化为各语义成分 $C$ ，再将语义成分 $C$ 注入到实例（代码向量）$x_i^s$ 中，形成一个代码实例的综合表示向量 $\hat{x}_{i}^s$ 。

1. **生成语义成分**
	1. **执行输入及结果**：输入第二步产生的描述原型 $\hat{d}$  ，利用注意力机制，进一步提取出不同的语义成分，且可以突出重要的语义成分。输出 $C$ 来表示语义成分。
	2. **公式的含义**：
		1. 首先姑且认为 $W_3$ 是一个 $c\times k$ 的矩阵，那么 $\hat{d}\,\cdot\,W_3$ 实际上就是将  $\hat{d}$  中的每一个 token 都映射为了一个 $k$ 维向量；
		2. 记 $A=\text{Softmax}\bigl(W_5 \,\cdot\, \text{ReLU}\bigl(W_4 (\hat{d}\,\cdot\,W_3)^T\bigr)\bigr)$ ，实际上是对 $\hat{d}$ 做了一系列的线性变换，得到了一个结果，称之为“语义成分”。 $A$ 的每一行实际上对应每一个语义成分对于各 token 的注意力分布，也即各个 token 在生成该语义成分的贡献占比。其中引入了非线性特性，即 $\text{ReLU}$ 函数能保留重要特征；引入 $\text{Softmax}$ 函数，将实际分值转化为概率分布的权重，且能够突出重要的成分。对于 $N$ 维向量 $s$ ：$$\text{Softmax}(s_i)=\frac{e^{s_i}}{\sum_{j=1}^N e^{s_j}}$$
		3. 最后 $C=A\cdot (\hat{d}\cdot W_3)$ ，实际上就是将每一个语义成分根据其注意力分布映射为一个 $k$ 维向量。可以用 $C_i$ 来表示第 $i$ 个语义成分。
	
2. **实现代码实例与语义成分对齐**
	1. **执行输入及结果**：输入上一步得到的语义成分 $C$ 和“上下文语义表示”这一操作得到的实例（代码向量）$x_i^s$ ，根据该实例中所有 token $h_z$ 与各语义成分的相似度，进行加权求和，最终可以获得一个代码实例的综合表示向量 $\hat{x}_{i}^s$ 。
	2. **公式的含义**：
		1. 对于某一 token $h_z$ 和某一语义成分 $C_l$ 相似度的衡量，论文中采用了余弦相似度：$$\text{cos}(h_z,C_l)=\frac{h_z\cdot C_l}{||h_z||\cdot ||C_l||}$$
		2. 对于每一个 token $h_z$ ，只关注哪个语义成分和该 token 最相似，也即该 token 在哪个语义角度最突出：$$s_z=\max_{l}(\text{cos}(h_z, C_l))$$
		3. $s_z$ 用参数 $\alpha, \beta$ 调整过后，使用 $\text{Softmax}$ 函数归一化，转化为概率分布，最终给每一个 token 分配一个权重，高相似度的 token 获得的权重更大：$$\text{weight}_z = \text{Softmax}\bigl(\alpha \cdot \beta \cdot s_z\bigr)$$
		4. 最终加权处理。此时与某语义成分联系更紧密的 token 对于最终的贡献更大，这也就使得代码实例融入了语义成分信息。




