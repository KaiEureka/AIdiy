
# **背景**

代码漏洞种类很多，知晓类型有助于修复漏洞，所以分类工作很重要，由此有了本文。

传统的分类方法需要大量的标记数据，就是说我得有一堆已经知道是什么漏洞的代码样本去训练一个分类器。但问题是，新漏洞出现后，收集和标记这些新样本特别费时间和精力。所以，这篇论文提出了一个新方法 **VulnSense**，用一种叫GZSL的技术来解决这个问题。

---

代码漏洞在本文中被分为以下两类：
- **Seen classes**：就是那些我们有很多代码样本的漏洞类型，比如常见的“整数溢出”。
- **Unseen classes**：就是新冒出来的、没有或只有很少样本的漏洞类型，但由于实际上的Unseen classes较少且难以测试，所以作者们实际上是把测试集中相当一部分的已知类型给定义为了“Unseen classes”，相当于是测试集。从而验证模型的该功能，确保面对真正的Unseen classes时可以给出靠谱的结果。

**VulnSense 的输入** 有三部分：
1. Seen classes 的代码样本
2. Seen classes 的描述
3. Unseen classes 的描述
注意，这里没有 unseen classes 的代码样本。VulnSense 的目标是训练一个模型，既能分类 seen classes 的代码，也能分类 unseen classes 的代码。

---

# **VulnSense 的工作流程**

## **1. 上下文语义表示（Contextualized Semantic Representation）**

- **工具**：使用 **GraphCodeBERT**，这是一个专为代码设计的预训练模型，基于Transformer架构，内部有12层编码器和12个头的多头注意力机制，能读懂代码的深层含义，不只是表面语法。比如，它能看出“a = a + b”这行代码在不同场景下可能有不同的作用。
- **处理流程**：
  1. 输入的代码实例和对漏洞的语义描述被拆分成一个个小的**token**，形成一个token序列。
  2. GraphCodeBERT对每个token进行处理，生成一个768维的**隐藏向量**，包含了代码的语义和上下文信息

---

## **2. 语义投影（Semantic Projection）**

这一步似乎是把“上一步中由对漏洞类型的自然语言描述转换而成的向量”和具体的这些类型的漏洞标签建立起联系，确保机器知道”这类漏洞的含义是这个向量，同时对数据进行降维处理。
### **技术细节**

输入”上一步中得出的向量，以及类型标签“，通过一个四个注意力头的 Transformer 编码器层和 FFN进行处理，由于我并未学完Transformer的那篇论文，所以不太理解输出是什么，但阅读后文我大概可以理解到输出是信息相互融合后的向量

然后，由于输入数据维度太高，需要用VAE把这些向量投影到一个低维空间，生成每个类别的原型向量（prototype），这个圆形向量就代表了类别的主要特征，我猜测可以提高计算速度同时避免过拟合（毕竟很多细枝末节的信息不如约去）。这一步用到了没学过的VAE,但是不难理解, 毕竟就是个数据降维的方法而已, 之前接触过其他方法

---

## **3. 原型引导的适应（Prototype-guided Adaptation）**
单纯的代码向量只知道代码的语义，但不知道它可能属于哪种漏洞。通过原型引导，模型能把代码和漏洞类型联系起来，即使是未知类别也能猜出来。由此完成了代码-描述-标签的整体联系。
### **技术细节**
- 输入第1步生成的代码向量 + 第2步生成的原型向量。然后通过**注意力机制**，让代码向量”关注“相关的原型向量，即可得到调整后的代码向量

这里真的好难懂，我能知道这步在干什么，但由于缺乏对transformer架构的了解，很难从字面意思上彻底理解这个过程到底发生什么，有空得先去读完那篇谷歌的attention is all your need了..

---

## **4. 对比学习（Contrastive Learning）**

对比学习模块旨在 **鼓励同一类实例的邻近性**，**促进不同类实例的分散**。

### **技术细节**
构建一个分类子问题，让模型区分和给定样本属于同一类别的样本（称为正样本）和与给定样本不属于同一类别的样本（称为负样本）, 然后训练模型区分正样本和负样本即可，具体而言使用**对比损失函数**，这个函数形式上很复杂，但并不难以理解,如此构建他们只是为了让它发挥衡量正样本相似度在总相似度中的占比的作用,从而在最小化损失函数的过程中达成"相同相聚, 不同相斥"的目的

最后，得到了一个优化后的特征空间，在这个特征空间中，类别区分更清晰。

##   5. 自校准模块（Self-Calibration Module）

**背景**
当一个模型仅在seen classes上进行训练时，会出现**偏见现象**, 具体来说就是在测试阶段，模型倾向于为已知类别分配很高的预测概率，而对未知类别的预测概率则被严重压制。作者指出这种现象在其他文献中也有类似观察。原因是训练数据中缺乏未知类别的样本，导致模型在面对未知类别时，倾向于将其错误分类为已知类别。

**目标**
自校准模块旨在减轻这种偏见，通过在训练时调整模型的预测概率分配，使得未知类别也能获得一定的非零概率，从而缓解了模型对已知类别的偏见，确保在训练时为未知类别保留一定的预测概率空间
### 技术实现

模型首先计算每个漏洞实例属于某个类别的概率如下：
$$
p(\hat{x}_i, \hat{d}_c) = \frac{\exp(\gamma \cos(\hat{x}_i, \hat{d}_c))}{\sum_{m=1}^{N_s + N_u} \exp(\gamma \cos(\hat{x}_i, \hat{d}_m))}$$
然后为了鼓励模型为未知类别分配更高的概率，自校准模块设计了以下损失函数：
$$
L_{sc} = -\log \left( \frac{1}{N_u} \sum_{m=N_s}^{N_s + N_u} p(\hat{x}_i, \hat{d}_m) \right)
$$
其作用是如果模型对未知类别的平均预测概率很低，则 损失函数就会很大，那么通过通过最小化 $L_{sc}$ ，模型被迫在训练时提高对未知类别的预测概率，从而避免完全偏向已知类别。

## 6. 算法流程

论文最终给出了一个基于该函数的算法全流程。
**算法 1** 总结了 VulnSense 模型的训练过程：
1. **输入**：训练步数、已知类别标签集、每个 episode 的类别数、每个类别的样本数、已知类别数据集、未知类别描述集。
2. **输出**：学习到的模型参数。
3. **步骤**：
   - 循环 \( $N_{\text{step}}$ \) 次，每次执行 \( E \) 个 episode。
   - 每个 episode：
     - 从 GraphCodeBERT 获取嵌入。
     - 拼接已知和未知类别的描述，生成混合原型。
     - 计算 VAE 损失、对比损失、自校准损失和交叉熵损失，得到总的损失函数。
     - 更新模型参数以最小化总损失。
#### **整个流程的串联**

1. **上下文语义表示**：把代码转成一个包含语义的向量。
2. **语义投影**：把漏洞描述转成每个类别的原型向量。
3. **原型引导的适应**：让代码向量学习原型信息，联系代码和漏洞类型。
4. **对比学习**：优化特征空间，让同类靠拢、异类远离。
5. **自校准**：平衡预测，确保未知类别不被忽略。

通过这五步，VulnSense能同时处理已知和未知类别的代码分类。尤其厉害的是，即使没有未知类别的代码样本，只靠描述也能准确识别新漏洞。


-----
# **训练和测试的过程**

- 以前的漏洞数据集不太适合用来做漏洞分类的研究，所以作者自己做了一个。这个数据集是从国际认可的 SARD里找的，里面有 16852 个漏洞文件，代表了 40 种漏洞类型。在实验的时候，把其中 25 种漏洞类型当作 “已见类”，这些类型的描述和实例都放进数据集里；剩下 15 种当作 “未见类”，模型训练的时候只用 “已见类” 的实例。而且，作者还进行了一大堆数据处理过程,简单地说, 把数据集中每个实例里和漏洞类型相关的 CWE - ID、类名、可能暴露漏洞类别的代码注释，还有一些像空格、换行、制表符这样的常见停用词都去掉了，还对一些简单的漏洞描述进行了补充，让不同漏洞类型的描述信息更平衡。最后，把每个 “已见类” 里 70% 的实例作为训练集，30% 作为测试集，所有 “未见类” 的实例都当作测试集,然后运行上述算法，模型学会怎么把代码样本映射到正确的漏洞类型。

- 对于分类结果, 用准确率（Acc）、精确率（Pre）、召回率（Rec）、F1 值（F1）和调和均值（HM）这些指标来评估 VulnSense 的效果，并和其他方法对比。这些指标通过真正例（TP）、假正例（FP）、假负例（FN）和真负例（TN）来计算，能从不同角度反映模型分类的好坏。

### **实验结果**

作者做了实验，证明 VulnSense 很厉害：
- **对 Seen classes**：跟 Bi - LSTM、Bi - GRU 等传统方法相比，发现分类效果可以和传统方法相媲美，误报率低，能有效识别漏洞。
- **对 Unseen classes**：比ReCapsNet、SEG、LTA 等其他 GZSL 方法强很多，能认出更多新漏洞。
- **消融实验**：去掉任何一个步骤（ GraphCodeBERT 组件、Transformer 编码器层组件、VAE 组件、原型引导适应（PA）过程、对比损失组件、自校准组件等），效果都会变差，说明每步都很重要。尤其是PA过程，实验结果表明，没有PA过程，模型在 “未见类” 测试集上准确率会变成 0%，原因很显然，模型压根不理解这些未见类标签对应什么含义。

---
# 后续工作
### **超参数的调优**

- **GraphCodeBERT**：处理代码时用了 12 层 transformer 和多头注意力机制（不过我感觉似乎这个参数调不了）
- **输入长度**：实验发现，代码序列长度设为 384 时效果最好，太短会漏掉关键逻辑，太长也没必要。
- **类别数量 (N)**：每轮训练用 5 个类别时效果最佳。
- **温度 (τ)**：对比学习中设为 1 时最优。

### **可视化证明**
- 用 t-SNE（一种降维工具, 尽可能保持距离信息的把高维点映射到二维）看特征分布，发现 VulnSense 能把不同漏洞类型的代码分得很开，效果比传统方法好，处理未见类型时虽然还有一些重叠，但已经能很好地将不同类别的实例分开了。

### 未来工作
文章开头提到的漏洞分类难的问题还是存在，虽然 VulnSense已经足够优秀，但相比在 “已见类” 测试集上表现不错，在 “未见类” 测试集上表现终究没那么好。这是因为广义零样本学习技术在漏洞分类上还存在局限性，漏洞的模式和上下文太复杂多样了，可见该工作未来还有进一步优化的空间。作者提出了使用LLM、其他GZSL方法、扩展为多标签分类、降低样本需求、开发嵌入式生成编码器等等未来工作

### **总结**
VulnSense 的核心是用漏洞的描述信息来分类新出现的漏洞类型，不用非得有大量代码样本。这对快速应对新漏洞特别有用，因为现实中不可能每次都花大力气收集新数据。它既能搞定老漏洞，也能认出新漏洞，是个实用价值很高的办法。

感觉只有模型的第二第三步不太理解,等补完transformer回头再看看没搞清楚的这部分